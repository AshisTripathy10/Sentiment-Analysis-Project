{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n",
      "WARNING:absl:options.experimental_threading is deprecated. Use options.threading instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test', 'train', 'unsupervised'])\n",
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "print(datasets.keys())\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples\n",
    "\n",
    "print(train_size , test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting  ...\n",
      "Label: 0 = Negative\n",
      "\n",
      "Review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However  ...\n",
      "Label: 0 = Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).take(1):\n",
    "    for review, label in zip(X_batch.numpy(), y_batch.numpy()):\n",
    "        print(\"Review:\", review.decode(\"utf-8\")[:200], \"...\")\n",
    "        print(\"Label:\", label, \"= Positive\" if label else \"= Negative\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 117), dtype=string, numpy=\n",
       " array([[b'This', b'was', b'an', b'absolutely', b'terrible', b'movie',\n",
       "         b\"Don't\", b'be', b'lured', b'in', b'by', b'Christopher',\n",
       "         b'Walken', b'or', b'Michael', b'Ironside', b'Both', b'are',\n",
       "         b'great', b'actors', b'but', b'this', b'must', b'simply', b'be',\n",
       "         b'their', b'worst', b'role', b'in', b'history', b'Even',\n",
       "         b'their', b'great', b'acting', b'could', b'not', b'redeem',\n",
       "         b'this', b\"movie's\", b'ridiculous', b'storyline', b'This',\n",
       "         b'movie', b'is', b'an', b'early', b'nineties', b'US',\n",
       "         b'propaganda', b'piece', b'The', b'most', b'pathetic', b'scenes',\n",
       "         b'were', b'those', b'when', b'the', b'Columbian', b'rebels',\n",
       "         b'were', b'making', b'their', b'cases', b'for', b'revolutions',\n",
       "         b'Maria', b'Conchita', b'Alonso', b'appeared', b'phony', b'and',\n",
       "         b'her', b'pseudo', b'love', b'affair', b'with', b'Walken',\n",
       "         b'was', b'nothing', b'but', b'a', b'pathetic', b'emotional',\n",
       "         b'plug', b'in', b'a', b'movie', b'that', b'was', b'devoid',\n",
       "         b'of', b'any', b'real', b'meaning', b'I', b'am', b'disappointed',\n",
       "         b'that', b'there', b'are', b'movies', b'like', b'this',\n",
       "         b'ruining', b\"actor's\", b'like', b'Christopher', b\"Walken's\",\n",
       "         b'good', b'name', b'I', b'could', b'barely', b'sit', b'through',\n",
       "         b'it'],\n",
       "        [b'I', b'have', b'been', b'known', b'to', b'fall', b'asleep',\n",
       "         b'during', b'films', b'but', b'this', b'is', b'usually', b'due',\n",
       "         b'to', b'a', b'combination', b'of', b'things', b'including',\n",
       "         b'really', b'tired', b'being', b'warm', b'and', b'comfortable',\n",
       "         b'on', b'the', b'sette', b'and', b'having', b'just', b'eaten',\n",
       "         b'a', b'lot', b'However', b'on', b'this', b'occasion', b'I',\n",
       "         b'fell', b'asleep', b'because', b'the', b'film', b'was',\n",
       "         b'rubbish', b'The', b'plot', b'development', b'was', b'constant',\n",
       "         b'Constantly', b'slow', b'and', b'boring', b'Things', b'seemed',\n",
       "         b'to', b'happen', b'but', b'with', b'no', b'explanation', b'of',\n",
       "         b'what', b'was', b'causing', b'them', b'or', b'why', b'I',\n",
       "         b'admit', b'I', b'may', b'have', b'missed', b'part', b'of',\n",
       "         b'the', b'film', b'but', b'i', b'watched', b'the', b'majority',\n",
       "         b'of', b'it', b'and', b'everything', b'just', b'seemed', b'to',\n",
       "         b'happen', b'of', b'its', b'own', b'accord', b'without', b'any',\n",
       "         b'real', b'concern', b'for', b'anything', b'else', b'I', b'cant',\n",
       "         b'recommend', b'this', b'film', b'at', b'all', b'<pad>',\n",
       "         b'<pad>', b'<pad>', b'<pad>', b'<pad>']], dtype=object)>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 0])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 900)\n",
    "    X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "    X_batch = tf.strings.split(X_batch)\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch\n",
    "preprocess(X_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch, y_batch in datasets[\"train\"].batch(2).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 402966),\n",
       " (b'the', 169165),\n",
       " (b'a', 95577),\n",
       " (b'and', 92590),\n",
       " (b'of', 85655)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83916"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [ word for word, count in vocabulary.most_common()[:vocab_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   38,    13,    12, 10053]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n",
    "table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  38   12   31 ...    0    0    0]\n",
      " [   7   21   74 ...    0    0    0]\n",
      " [4691 6619    1 ...    0    0    0]\n",
      " ...\n",
      " [  38   13  127 ...    0    0    0]\n",
      " [1966 4420  501 ...    0    0    0]\n",
      " [3592 5567    7 ...    0    0    0]], shape=(32, 168), dtype=int64)\n",
      "tf.Tensor([0 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch\n",
    "train_set = datasets[\"train\"].repeat().batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)\n",
    "test_set = datasets[\"test\"].batch(1000).map(preprocess)\n",
    "test_set = test_set.map(encode_words)\n",
    "for X_batch, y_batch in train_set.take(1):\n",
    "    print(X_batch)\n",
    "    print(y_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n",
    "               mask_zero=True,\n",
    "               input_shape=[None]),\n",
    "    keras.layers.GRU(4, return_sequences=True),\n",
    "    keras.layers.GRU(2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "781/781 [==============================] - 180s 221ms/step - loss: 0.5466 - accuracy: 0.7053\n",
      "Epoch 2/2\n",
      "781/781 [==============================] - 171s 219ms/step - loss: 0.3122 - accuracy: 0.8781\n",
      "Time of execution: 351.48623538017273\n",
      "25/25 [==============================] - 9s 259ms/step - loss: 0.3867 - accuracy: 0.8397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3867467939853668, 0.839680016040802]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model.fit(train_set, steps_per_epoch=train_size // 32, epochs=2)\n",
    "end = time.time()\n",
    "print(\"Time of execution:\", end-start)\n",
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
